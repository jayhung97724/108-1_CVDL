{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "np.set_printoptions(formatter={'float': '{: 0.6f}'.format})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of calibration images\n",
    "images = [cv2.imread(file) for file in glob.glob(\"../images/CameraCalibration/*.bmp\")]\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((8*11,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:8,0:11].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "cameraMatrix = []\n",
    "distCoeff = []\n",
    "rvec = [] \n",
    "tvec = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImages(images):\n",
    "    for img in images:\n",
    "        cv2.namedWindow(\"Show Image\", cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(\"Show Image\",img)\n",
    "        cv2.waitKey(2000)\n",
    "    cv2.destroyAllWindows()\n",
    "# showImages(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImage(img):\n",
    "    cv2.namedWindow(\"Show Image\", cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"Show Image\",img)\n",
    "    cv2.waitKey(2000)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q1_1():\n",
    "    global mtx, cameraMatrix, distCoeff, rvec, tvec, objpoints, imgpoints\n",
    "    # prepare object points\n",
    "    nx = 8\n",
    "    ny = 11\n",
    "    print('Q1.1 ...\\nFinding corners ...')\n",
    "    for img in images:\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "        \n",
    "        # If found, draw corners\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            corners2 = cv2.cornerSubPix(gray,corners,(11,11),(-1,-1),criteria)\n",
    "            imgpoints.append(corners2)\n",
    "            \n",
    "            # Draw and display the corners\n",
    "            cv2.drawChessboardCorners(img, (nx, ny), corners, ret)\n",
    "    print('Showing images ...')\n",
    "    showImages(images)\n",
    "    # Calibration\n",
    "    ret, cameraMatrix, distCoeff, rvec, tvec = cv2.calibrateCamera(objpoints, imgpoints, (2048, 2048), None, None)\n",
    "    np.savez('params.npz', cameraMatrix=cameraMatrix, distCoeff=distCoeff[0], rvec=rvec, tvec=tvec)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Q1_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     ret, cameraMatrix, distCoeff, rvec, tvec = cv2.calibrateCamera(objpoints, imgpoints, (2048, 2048), None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q1_2():\n",
    "    print('Q1_2 ...')\n",
    "    print(cameraMatrix)\n",
    "Q1_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q1_3(picIndex):\n",
    "    print('Q1_3 ...')\n",
    "    picIndex = picIndex-1\n",
    "    rotMat,_ = cv2.Rodrigues(rvec[picIndex])\n",
    "    print(np.concatenate((rotMat,tvec[picIndex]), axis=1))\n",
    "Q1_3(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q1_4():\n",
    "    print('Q1_4 ...')\n",
    "    print(distCoeff[0])\n",
    "Q1_4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previously saved data\n",
    "params = np.load('params.npz')\n",
    "mtx = params['cameraMatrix']\n",
    "dist = params['distCoeff']\n",
    "\n",
    "# Make a list of calibration images\n",
    "images2 = [cv2.imread(file) for file in glob.glob(\"../images/CameraCalibration/*.bmp\")]\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((8*11,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:8, 0:11].T.reshape(-1,2)\n",
    "\n",
    "axis = np.float32([[-1,-1,0], [-1,1,0], \n",
    "                   [1,1,0], [1,-1,0], [0,0,-2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(img, corners, imgpts):\n",
    "    for i in range(0, 4):\n",
    "        j = (i + 1) if i < 3 else 0\n",
    "        img = cv2.line(img, tuple(imgpts[i].ravel()), tuple(imgpts[j].ravel()), (0,0,255), 3)\n",
    "        img = cv2.line(img, tuple(imgpts[i].ravel()), tuple(imgpts[4].ravel()), (0,0,255), 3)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q2():\n",
    "    for img in images2[:5]:\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (8,11),None)\n",
    "\n",
    "        if ret == True:\n",
    "            corners2 = cv2.cornerSubPix(gray,corners,(11,11),(-1,-1),criteria)\n",
    "\n",
    "            # Find the rotation and translation vectors.\n",
    "            _, rvecs, tvecs, inliers = cv2.solvePnPRansac(objp, corners2, mtx, dist[0])\n",
    "\n",
    "            # project 3D points to image plane\n",
    "            imgpts, jac = cv2.projectPoints(axis, rvecs, tvecs, mtx, dist)\n",
    "\n",
    "            img = draw(img,corners2,imgpts)\n",
    "            showImage(img)\n",
    "\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q4():\n",
    "    img = cv2.imread('../../images/Contour.png')\n",
    "    imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret,thresh = cv2.threshold(imgray,127,255,0)\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cv2.drawContours(img, contours, -1, (0,0,255), 2)\n",
    "    showImage(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImageOSize(img):\n",
    "    cv2.namedWindow(\"Show Image\")\n",
    "    cv2.imshow(\"Show Image\",img)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q3_1(angle=45, scale=0.8, Tx=150, Ty=50):   \n",
    "    print('Q3.1 ...')\n",
    "    img = cv2.imread('../../images/OriginalTransform.png')\n",
    "    print('Showing Original image\\nPress any key to continue ...')\n",
    "    showImageOSize(img)\n",
    "    rows,cols = img.shape[:2]\n",
    "    center = (125+Tx, 130+Ty)\n",
    "    \n",
    "    print(center)\n",
    "    TM = np.float32([[1,0,Tx],[0,1,Ty]])\n",
    "    RM = cv2.getRotationMatrix2D(center,angle,1)\n",
    "\n",
    "    img = cv2.warpAffine(img,TM,(cols,rows))\n",
    "    img = cv2.warpAffine(img,RM,(cols,rows))\n",
    "    img = cv2.resize(img,None,fx=scale, fy=scale, interpolation = cv2.INTER_AREA)\n",
    "    print('Showing transformed image ...')\n",
    "    showImageOSize(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3.1 ...\n",
      "Showing Original image\n",
      "Press any key to continue ...\n",
      "(275, 180)\n",
      "Showing transformed image ...\n"
     ]
    }
   ],
   "source": [
    "# Q3_1(45, 0.8, 0, 100)\n",
    "# Q3_1(45, 0.8, 100, 0)\n",
    "Q3_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
